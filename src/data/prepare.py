"""Utilities for preparing the SDSS dataset used in the notebooks."""
from __future__ import annotations

from pathlib import Path
from typing import Iterable, Tuple

import pandas as pd

# Default configuration used across notebooks and scripts
RAW_DATA_PATH = Path("data/raw/sdss.csv")
PROCESSED_DATA_PATH = Path("data/processed/sdss_clean.csv")
FEATURE_COLUMNS: Tuple[str, ...] = ("redshift", "i", "u", "g", "r", "z")
TARGET_COLUMN = "class"
CLASS_MAPPING = {"STAR": 0, "GALAXY": 1, "QSO": 2}


def load_raw_data(path: Path = RAW_DATA_PATH) -> pd.DataFrame:
    """Load the raw SDSS catalogue exported as CSV.

    The file generated by SDSS includes a comment line at the top, so we
    remove it with ``skiprows=1``.
    """

    return pd.read_csv(path, skiprows=1)


def encode_target(df: pd.DataFrame, mapping: dict[str, int] | None = None) -> pd.DataFrame:
    """Map the string labels to numeric values expected by the models."""

    mapping = mapping or CLASS_MAPPING
    encoded = df.copy()
    encoded[TARGET_COLUMN] = encoded[TARGET_COLUMN].map(mapping)
    return encoded


def select_features(
    df: pd.DataFrame, features: Iterable[str] = FEATURE_COLUMNS
) -> tuple[pd.DataFrame, pd.Series]:
    """Split the dataframe into the feature matrix and the encoded target."""

    feature_frame = df[list(features)].copy()
    target_series = df[TARGET_COLUMN].copy()
    return feature_frame, target_series


def prepare_dataset(
    raw_path: Path = RAW_DATA_PATH,
    output_path: Path = PROCESSED_DATA_PATH,
    features: Iterable[str] = FEATURE_COLUMNS,
    mapping: dict[str, int] | None = None,
) -> pd.DataFrame:
    """Load, clean and persist the dataset used for modelling.

    Parameters
    ----------
    raw_path:
        Location of the raw CSV file downloaded from SDSS.
    output_path:
        File where the cleaned dataset will be stored.
    features:
        Collection of feature names to keep in the final dataset.
    mapping:
        Optional custom mapping between textual classes and integers.
    """

    df = load_raw_data(raw_path)
    df = encode_target(df, mapping)
    feature_frame, target_series = select_features(df, features)
    processed = feature_frame.assign(**{TARGET_COLUMN: target_series})

    output_path.parent.mkdir(parents=True, exist_ok=True)
    processed.to_csv(output_path, index=False)
    return processed


def main() -> None:
    prepared = prepare_dataset()
    print(
        "Dataset salvo em",
        PROCESSED_DATA_PATH,
        f"com {len(prepared)} linhas e {len(prepared.columns)} colunas.",
    )


if __name__ == "__main__":
    main()
